{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfa9fb6",
   "metadata": {},
   "source": [
    "First thing first, let’s install the libraries that we will need. We can use PIP install, which is a python library management tool. We can install multiple libraries in one line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8aadac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fada8a",
   "metadata": {},
   "source": [
    "RAVDESS stands for Ryerson Audio-Visual Database of Emotional Speech and Song. It is a large dataset will an audio and video database. The original size of this data is around 24Gb. But we will use a smaller portion of it and not the whole dataset. This will help us to stay focused, train our model faster and to keep things simple. The small portion of the dataset can be found https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadabfa",
   "metadata": {},
   "source": [
    "This portion of the RAVDESS contains 1440 files: 60 trials per actor x 24 actors = 1440. The data contains 24 professional actors: 12 female and 12 male. Speech emotions include calm, happy, sad, angry, fearful, surprise, and disgust expressions. You can learn more on the Kaggle website.\n",
    "The file names are renamed following a particular pattern. This pattern consists of 7 parts. And these parts are divided as following: Modality, Vocal channel, Emotion, Emotional intensity, Statement, Repetition, and Actor. Each information also has its sub-division. All this information is labeled; you can find more about these on the Kaggle website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae63fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e2226",
   "metadata": {},
   "source": [
    "This function will extract audio recordings and return them as stack arrays in sequence horizontally using a numpy hstack method.\n",
    "There are many features of audio files. And some of them are MFCC, Chroma and Mel.\n",
    "\n",
    "mfcc: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound\n",
    "chroma: Pertains to the 12 different pitch classes\n",
    "mel: Mel Spectrogram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60c0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#DataFlair - Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e480e64",
   "metadata": {},
   "source": [
    "We are going to create this dictionary to use when training the machine learning model. And after the labels, we are creating a list of emotions that we want to focus in this project. It’s hard to do a prediction using all emotions, because the speech may sound in more than one emotion simultaneously, and that will affect our prediction scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213f4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"D:\\\\ArdentML\\\\project\\\\data_set\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5522f",
   "metadata": {},
   "source": [
    "In this step, we are going to define a function to load our dataset. First, we are loading the data and then extracting the features using the function defined in the previous step. While features are extracting, we are assigning the features with the labels emotions. You can think of features as our input (x) and the labeled emotion as an output (y). This is a well-known machine learning model, also known as Supervised Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94686d",
   "metadata": {},
   "source": [
    " we are going to split the labeled dataset using the train_test_split() function. It is a well-known splitting function by Scikit-learn module. It divides the dataset into four chunks. We can define how much of the dataset we want to use for training and how much for testing. You can adjust these values to see how it affects the prediction. There is no one size fits all rule; it usually depends on the dataset. But in most cases, the 0.25 test size is applied. This means 3/4 of dataset is used for training and 1/4 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a096a",
   "metadata": {},
   "source": [
    "________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434d17f",
   "metadata": {},
   "source": [
    "We are almost done. This is the final step, where will start calling the functions we defined earlier and recognizing emotions from speech audio recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28eea22a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10296/3608615611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10296/3485799242.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(test_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\\\ArdentML\\\\project\\\\data_set\\\\Actor_*\\\\*.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0memotion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0memotions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96312c47",
   "metadata": {},
   "source": [
    "Let’s start by running the load_data() function. This function will return four lists. That’s we are going to use four different variables for each list — the order matters. You should be familiar with this splitting method, especially if you are working with machine learning projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6ed676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573, 191)\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52a69b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "506c6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', \n",
    "                    max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798ef95",
   "metadata": {},
   "source": [
    "MLP Classifier is multi-layer perceptron classifier. It uses a neural network model to optimize the log-loss function using Limited memory BFGS or stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9ee22f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cd4dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0b6921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy' 'happy' 'happy' 'fearful' 'fearful' 'fearful' 'calm' 'fearful'\n",
      " 'calm' 'disgust' 'fearful' 'calm' 'calm' 'happy' 'disgust' 'happy'\n",
      " 'happy' 'fearful' 'disgust' 'disgust' 'calm' 'fearful' 'calm' 'calm'\n",
      " 'happy' 'happy' 'happy' 'disgust' 'happy' 'calm' 'happy' 'calm' 'happy'\n",
      " 'fearful' 'happy' 'fearful' 'fearful' 'fearful' 'calm' 'happy' 'happy'\n",
      " 'calm' 'fearful' 'calm' 'calm' 'calm' 'happy' 'calm' 'calm' 'fearful'\n",
      " 'disgust' 'fearful' 'fearful' 'happy' 'happy' 'fearful' 'calm' 'happy'\n",
      " 'calm' 'calm' 'calm' 'disgust' 'disgust' 'happy' 'disgust' 'happy'\n",
      " 'happy' 'happy' 'happy' 'happy' 'fearful' 'fearful' 'disgust' 'fearful'\n",
      " 'fearful' 'disgust' 'fearful' 'fearful' 'calm' 'happy' 'calm' 'fearful'\n",
      " 'calm' 'calm' 'disgust' 'fearful' 'calm' 'fearful' 'fearful' 'fearful'\n",
      " 'disgust' 'calm' 'calm' 'disgust' 'disgust' 'fearful' 'fearful' 'fearful'\n",
      " 'fearful' 'happy' 'happy' 'disgust' 'disgust' 'calm' 'disgust' 'calm'\n",
      " 'disgust' 'happy' 'fearful' 'happy' 'fearful' 'happy' 'fearful' 'fearful'\n",
      " 'disgust' 'disgust' 'calm' 'happy' 'calm' 'calm' 'fearful' 'calm' 'happy'\n",
      " 'happy' 'disgust' 'calm' 'happy' 'fearful' 'happy' 'fearful' 'calm'\n",
      " 'happy' 'happy' 'fearful' 'fearful' 'happy' 'fearful' 'happy' 'happy'\n",
      " 'fearful' 'calm' 'happy' 'happy' 'happy' 'happy' 'disgust' 'happy'\n",
      " 'disgust' 'happy' 'calm' 'calm' 'happy' 'fearful' 'calm' 'fearful'\n",
      " 'happy' 'calm' 'calm' 'disgust' 'fearful' 'disgust' 'happy' 'fearful'\n",
      " 'calm' 'happy' 'happy' 'fearful' 'happy' 'calm' 'happy' 'fearful'\n",
      " 'fearful' 'disgust' 'fearful' 'happy' 'happy' 'disgust' 'disgust' 'happy'\n",
      " 'happy' 'happy' 'fearful' 'calm' 'calm' 'calm' 'happy' 'happy' 'calm'\n",
      " 'fearful' 'happy' 'happy']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "297fd7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.30%\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e0a5e",
   "metadata": {},
   "source": [
    "Our accuracy score is 73.3, and that is pretty impressive. I usually get a similar score after fitting the model multiple times. I do think that this is a satisfying score for an emotion recognition model, which was trained by audio recordings. Thanks to machine learning and artificial intelligence model developers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6fad7",
   "metadata": {},
   "source": [
    "______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc47011",
   "metadata": {},
   "source": [
    "Dumping our model in a pickele file accessing it to predict file and join it to the frontend made using streamlit framework using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e64b3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "602abb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pickle','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0801a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pickle','rb') as f:\n",
    "    mp= pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e8de8",
   "metadata": {},
   "source": [
    "THANK you  We have created a speech emotion recognizer using python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788aa09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
